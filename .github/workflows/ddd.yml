name: CI with Persistent Environment (v7.4 - Chroot Only Debug Fixed SSH Custom)

on:
  workflow_dispatch:
    inputs:
      backup_mode:
        description: 'âœ… [æ ¸å¿ƒ] é€‰æ‹©åœ¨ç»“æŸæ—¶åˆ›å»ºçš„çŽ¯å¢ƒå¤‡ä»½æ¨¡å¼'
        required: true
        type: choice
        default: 'none'
        options:
          - 'none'
          - 'chroot'
      run_startup_script: { description: 'ðŸš€ [æ ¸å¿ƒ] æ˜¯å¦è‡ªåŠ¨æ‰§è¡ŒChrootå†…çš„æœåŠ¡å¯åŠ¨è„šæœ¬?', required: true, type: boolean, default: true }
      enable_ssh: { description: 'ðŸž [è°ƒè¯•] æ˜¯å¦å¯ç”¨SSHæ‰‹åŠ¨è°ƒè¯• (å°†æš‚åœè‡ªåŠ¨åŒ–) ?', required: true, type: boolean, default: false }
      ssh_timeout_minutes: { description: 'â³ SSHä¼šè¯è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰', required: false, type: number, default: 350 }
      run_yunzai: { description: '  - æ˜¯å¦å¯åŠ¨ Yunzai-Bot æœåŠ¡? (åŒ…å« launcher)', type: boolean, default: true }
      run_loophole_webdav: { description: '  - æ˜¯å¦å¯åŠ¨ Loophole WebDAV éš§é“?', type: boolean, default: true }
      enable_napcat_tunnel: { description: '  - (Loophole) æ˜¯å¦é¢å¤–å¯ç”¨ Napcat å†…ç½‘ç©¿é€?', type: boolean, default: false }
      run_chmlfrp: { description: '  - æ˜¯å¦å¯åŠ¨ ChmlFrp æœåŠ¡? (åŒ…å« openlist)', type: boolean, default: true }
  schedule:
    - cron: '10 12 * * 5'
    - cron: '0 16 * * 5'
    - cron: '0 22 * * 5'
    - cron: '0 4 * * 6'
    - cron: '0 10 * * 6'
    - cron: '0 16 * * 6'
    - cron: '0 22 * * 6'

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

env:
  CHROOT_DIR: /mnt/minisys
  BACKUP_PREFIX: minisys_backup_
  B2_REMOTE_NAME: "b2_storage"
  B2_REMOTE_PATH: "backup"
  RCLONE_FLAGS: "--multi-thread-streams 4 --buffer-size 64M --fast-list --transfers 8 --progress"
  PAT: ${{ secrets.PAT }}
  LOOPHOLE_WEBDAV_USER: ${{ secrets.LOOPHOLE_WEBDAV_USER }}
  LOOPHOLE_WEBDAV_PASS: ${{ secrets.LOOPHOLE_WEBDAV_PASS }}
  LOOPHOLE_WEBDAV_HOSTNAME: ${{ secrets.LOOPHOLE_WEBDAV_HOSTNAME }}
  LOOPHOLE_NAPCAT_HOSTNAME: ${{ secrets.LOOPHOLE_NAPCAT_HOSTNAME }}
  NAPCATUSER: ${{ secrets.NAPCATUSER }}
  NAPCATPASS: ${{ secrets.NAPCATPASS }}
  B2_KEY_ID: ${{ secrets.B2_KEY_ID }}
  B2_APPLICATION_KEY: ${{ secrets.B2_APPLICATION_KEY }}
  B2_BUCKET_NAME: ${{ secrets.B2_BUCKET_NAME }}
  B2_DOWNLOAD_URL: ${{ secrets.B2_DOWNLOAD_URL }}
  CLOUDFLARE_TUNNEL_TOKEN: ${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}

jobs:
  build-and-run-all:
    name: "Run All Services (v7.4)"
    runs-on: ubuntu-latest
    steps:
      - name: 1. Checkout Workflow Code
        uses: actions/checkout@v4

      - name: 2. Maximize Runner Disk Space
        run: |
          sudo rm -rf /usr/share/dotnet /opt/ghc /usr/local/share/boost "$AGENT_TOOLSDIRECTORY"
          sudo apt-get autoremove -y && sudo apt-get autoclean -y
          sudo rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*
          sudo docker system prune -a -f || true
          echo "âœ… Disk space optimized. Available: $(df -h / | tail -1 | awk '{print $4}')"

      - name: 3. Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y debootstrap rclone pigz zstd jq

      - name: 4. Setup Python Environment
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: 5. Clone Python Application
        run: git clone https://x-access-token:${{ env.PAT }}@github.com/Jyf0214/chatgpt-on-wechat.git

      - name: 6. Cache Python Dependencies (Pip)
        uses: actions/cache@v4
        with:
          path: ./chatgpt-on-wechat/lib
          key: ${{ runner.os }}-pip-deps-${{ hashFiles('./chatgpt-on-wechat/requirements.txt', './chatgpt-on-wechat/requirements-optional.txt') }}

      - name: 7. âš¡ï¸ Prepare Environment in Parallel
        id: prepare_all
        run: |
          retry() {
            local retries=$1; shift; local count=0
            until "$@"; do
              exit_code=$?; count=$((count + 1))
              if [ $count -lt "$retries" ]; then
                echo "Command failed (Exit code: $exit_code), retrying ($count/$retries)..."; sleep 5
              else
                echo "Command failed after $retries retries."; return $exit_code
              fi
            done
            return 0
          }
          echo "--- Starting Phase 1: Parallel Downloads ---"
          (
            rclone config create ${{ env.B2_REMOTE_NAME }} b2 account "${{ env.B2_KEY_ID }}" key "${{ env.B2_APPLICATION_KEY }}" download_url "${{ env.B2_DOWNLOAD_URL }}"
            B2_FULL_PATH="${{ env.B2_REMOTE_NAME }}:${{ env.B2_BUCKET_NAME }}/${{ env.B2_REMOTE_PATH }}"
            LATEST_BACKUP_FILENAME=$(rclone lsjson ${B2_FULL_PATH}/ | jq -r '[.[] | select(.Name | test("minisys_backup_.*\\.tar\\.(zst|gz)$"))] | sort_by(.ModTime) | .[-1].Name' 2>/dev/null)
            if [[ -n "$LATEST_BACKUP_FILENAME" && "$LATEST_BACKUP_FILENAME" != "null" ]]; then
              echo "   -> [A] Found backup: ${LATEST_BACKUP_FILENAME}. Downloading..."
              retry 3 rclone copyto "${B2_FULL_PATH}/${LATEST_BACKUP_FILENAME}" "/tmp/backup.archive" ${{ env.RCLONE_FLAGS }}
              echo "$LATEST_BACKUP_FILENAME" > /tmp/chroot_backup_info
            fi
          ) &
          CHROOT_DOWNLOAD_PID=$!
          (
            echo "   -> [B] Downloading Node.js v20 setup script..."
            retry 3 curl -fsSL https://deb.nodesource.com/setup_20.x -o /tmp/nodesource_setup.sh
          ) &
          NODE_DOWNLOAD_PID=$!
          
          wait $CHROOT_DOWNLOAD_PID; EXIT_A=$?
          wait $NODE_DOWNLOAD_PID;   EXIT_B=$?
          if [ $EXIT_A -ne 0 ] || [ $EXIT_B -ne 0 ]; then echo "âŒ Phase 1 download failed! Chroot: $EXIT_A, Node: $EXIT_B"; exit 1; fi
          
          echo "--- Starting Phase 2: Parallel Local Setup ---"
          (
            sudo mkdir -p ${{ env.CHROOT_DIR }}
            if [ -f "/tmp/backup.archive" ]; then
              echo "   -> [A] Extracting Chroot backup..."
              LATEST_BACKUP_FILENAME=$(cat /tmp/chroot_backup_info)
              if [[ "${LATEST_BACKUP_FILENAME}" == *.zst ]]; then unzstd -c /tmp/backup.archive | sudo tar -xpf - -C ${{ env.CHROOT_DIR }}; else pigz -dc /tmp/backup.archive | sudo tar -xpf - -C ${{ env.CHROOT_DIR }}; fi
              echo "restored=true" > /tmp/chroot_status
            else
              echo "   -> [A] No backup found. Creating new system with debootstrap..."
              sudo debootstrap --variant=minbase jammy ${{ env.CHROOT_DIR }} http://archive.ubuntu.com/ubuntu/
              echo "restored=false" > /tmp/chroot_status
            fi
            rm -f /tmp/backup.archive
          ) &
          CHROOT_INSTALL_PID=$!
          (
            echo "   -> [B] Installing Node.js v20 and PM2 on host..."
            sudo -E bash /tmp/nodesource_setup.sh
            sudo apt-get install -y nodejs
            sudo npm install -g pm2
          ) &
          NODE_INSTALL_PID=$!

          wait $CHROOT_INSTALL_PID; EXIT_A=$?
          wait $NODE_INSTALL_PID;   EXIT_B=$?
          if [ $EXIT_A -ne 0 ] || [ $EXIT_B -ne 0 ]; then echo "âŒ Phase 2 local setup failed! Chroot: $EXIT_A, Node: $EXIT_B"; exit 1; fi
          
          echo "âœ… Environment preparation complete."
          CHROOT_STATUS=$(cat /tmp/chroot_status); echo "restored=${CHROOT_STATUS}" >> $GITHUB_OUTPUT

      - name: 8. Install & Start Python Application
        run: |
          nohup bash -c 'cd chatgpt-on-wechat && python -m pip install --upgrade pip && pip install -r requirements.txt --target ./lib --cache-dir ~/.cache/pip || true && export PYTHONPATH=$(pwd)/lib && pm2 start "python3 app.py" --name "python-app"' > install.log 2>&1 &

      - name: 9. Mount Virtual Filesystems
        run: |
          MNT_DIR=${{ env.CHROOT_DIR }}; sudo mount -t proc proc "${MNT_DIR}/proc"; sudo mount -o bind /dev "${MNT_DIR}/dev"; sudo mount -o bind /dev/pts "${MNT_DIR}/dev/pts"; sudo mount -o bind /sys "${MNT_DIR}/sys"

      - name: 10. Prepare Chroot Environment
        run: |
          echo "--- Preparing Chroot: Installing Node.js v20 & Updating OpenList ---"
          sudo chroot ${{ env.CHROOT_DIR }} /bin/bash -c "apt-get clean && apt-get update && apt-get install -y curl && curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && apt-get install -y nodejs && npm install -g pm2"
          sudo tee ${{ env.CHROOT_DIR }}/tmp/update_openlist.sh > /dev/null << 'EOF'
          #!/bin/bash
          set -e; cd /root; apt-get update >/dev/null && apt-get install -y curl jq wget >/dev/null; curl -fsSL http://bash.skadi.kozow.com/scripts/update_openlist.sh | bash
          EOF
          sudo chmod +x ${{ env.CHROOT_DIR }}/tmp/update_openlist.sh; sudo chroot ${{ env.CHROOT_DIR }} /tmp/update_openlist.sh

      - name: 11A. Start Services or Wait for Debugging
        if: github.event_name == 'schedule' || github.event.inputs.run_startup_script == 'true'
        env:
          RUNTIME_MINUTES: ${{ (github.event.inputs.backup_mode == 'chroot' || github.event.inputs.backup_mode == 'all') && 90 || 350 }}
        run: |
          echo "âœ… Preparing to start services inside Chroot..."
          sudo tee ${{ env.CHROOT_DIR }}/tmp/startup.sh > /dev/null << 'EOF'
          #!/bin/bash
          set -e
          export RUN_YUNZAI='${{ github.event.inputs.run_yunzai || (github.event_name == 'schedule' && 'true') }}'; export RUN_LOOPHOLE_WEBDAV='${{ github.event.inputs.run_loophole_webdav || (github.event_name == 'schedule' && 'true') }}'; export RUN_CHMLFRP='${{ github.event.inputs.run_chmlfrp || (github.event_name == 'schedule' && 'true') }}'; export ENABLE_NAPCAT_TUNNEL='${{ github.event.inputs.enable_napcat_tunnel || 'false' }}'
          export LOOPHOLE_WEBDAV_USER='${{ env.LOOPHOLE_WEBDAV_USER }}'; export LOOPHOLE_WEBDAV_PASS='${{ env.LOOPHOLE_WEBDAV_PASS }}'; export LOOPHOLE_WEBDAV_HOSTNAME='${{ env.LOOPHOLE_WEBDAV_HOSTNAME }}'; export LOOPHOLE_NAPCAT_HOSTNAME='${{ env.LOOPHOLE_NAPCAT_HOSTNAME }}'; export NAPCATUSER='${{ env.NAPCATUSER }}'; export NAPCATPASS='${{ env.NAPCATPASS }}'
          export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/node_modules/.bin; HOME_DIR="/root"
          echo "--- [Chroot] Starting services... ---"
          if ! command -v pm2 &> /dev/null; then npm install -g pm2; fi
          pm2 flush
          command -v redis-server &> /dev/null && redis-server --daemonize yes || echo "  -> Warning: redis-server not found."
          if [[ "$RUN_YUNZAI" == "true" ]]; then (cd "${HOME_DIR}" && pm2 start ./launcher.sh --name "launcher") || echo "  -> Warning: launcher.sh not found."; (cd "${HOME_DIR}/Yunzai" && pm2 start app.js --name "yunzai-app") || echo "  -> Warning: Yunzai dir not found."; else echo "  -> Skipping Yunzai-Bot."; fi
          if [[ "$RUN_LOOPHOLE_WEBDAV" == "true" ]]; then if [ -f "${HOME_DIR}/loophole/loophole" ]; then cd "${HOME_DIR}/loophole"; pm2 start ./loophole --name "loophole-webdav" -- webdav ~ -u "${LOOPHOLE_WEBDAV_USER}" -p "${LOOPHOLE_WEBDAV_PASS}" --hostname "${LOOPHOLE_WEBDAV_HOSTNAME}"; if [[ "$ENABLE_NAPCAT_TUNNEL" == "true" ]]; then pm2 start ./loophole --name "loophole-http" -- http 6099 --hostname "${LOOPHOLE_NAPCAT_HOSTNAME}" --basic-auth-username "${NAPCATUSER}" --basic-auth-password "${NAPCATPASS}"; fi; else echo "  -> Warning: loophole not found."; fi; else echo "  -> Skipping Loophole."; fi
          if [[ "$RUN_CHMLFRP" == "true" ]]; then (cd "${HOME_DIR}" && pm2 start openlist --name "openlist-server" -- server) || echo "  -> Warning: openlist not found."; (cd "${HOME_DIR}/ChmlFrp" && pm2 start ./frpc --name "chml-frp" -- -c frpc.ini) || echo "  -> Warning: frpc not found."; else echo "  -> Skipping ChmlFrp."; fi
          pm2 save && pm2 ls
          EOF
          sudo chmod +x ${{ env.CHROOT_DIR }}/tmp/startup.sh; sudo chroot ${{ env.CHROOT_DIR }} /tmp/startup.sh
          echo "ðŸš€ Services started."
          
          if [[ "${{ github.event_name }}" == 'schedule' || "${{ github.event.inputs.enable_ssh }}" == 'false' ]]; then
            echo "Workflow running for ${RUNTIME_MINUTES} minutes..."
            sleep ${RUNTIME_MINUTES}m
            echo "â³ Runtime finished."
          else
            echo "SSH is enabled. Workflow will pause for manual debugging."
          fi

      - name: 11B. Enable SSH for Manual Debugging
        if: github.event.inputs.enable_ssh == 'true'
        run: |
          set -e
          if [[ -z "${{ env.CLOUDFLARE_TUNNEL_TOKEN }}" ]]; then
            echo "::error:: CLOUDFLARE_TUNNEL_TOKEN secret not found."
            exit 1
          fi

          NEW_USER=${{ github.repository_owner }}
          NEW_HOSTNAME=$(echo "${{ github.repository }}" | tr '/' '-')
          
          echo "--- Setting up personalized SSH environment ---"
          sudo hostname "${NEW_HOSTNAME}"
          sudo useradd -m -s /bin/bash "${NEW_USER}"
          sudo usermod -aG sudo "${NEW_USER}"
          echo "${NEW_USER} ALL=(ALL) NOPASSWD: ALL" | sudo tee "/etc/sudoers.d/${NEW_USER}"

          sudo apt-get update && sudo apt-get install -y openssh-server
          
          AUTHORIZED_KEYS_FILE="/home/${NEW_USER}/.ssh/authorized_keys"
          sudo mkdir -p "/home/${NEW_USER}/.ssh"
          curl -fsL "https://api.github.com/users/${NEW_USER}/keys" | jq -r '.[].key' | sudo tee "${AUTHORIZED_KEYS_FILE}" > /dev/null
          sudo chown -R "${NEW_USER}:${NEW_USER}" "/home/${NEW_USER}/.ssh"
          sudo chmod 700 "/home/${NEW_USER}/.ssh" && sudo chmod 600 "${AUTHORIZED_KEYS_FILE}"
          sudo service ssh start

          echo "--- Starting Cloudflared tunnel ---"
          wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared
          chmod +x cloudflared
          nohup ./cloudflared tunnel --no-autoupdate run --token ${{ env.CLOUDFLARE_TUNNEL_TOKEN }} &
          sleep 8
          
          echo "===================================================================================="
          echo "âœ… SSH Ready. Connect with your Cloudflare Tunnel hostname."
          echo ""
          echo "   ssh ${NEW_USER}@(your-tunnel-hostname.com)"
          echo ""
          echo "   Your shell prompt will be: ${NEW_USER}@${NEW_HOSTNAME}:~$"
          echo ""
          echo "   [TIP] If connection fails with a 'Host key verification failed' error,"
          echo "   run this command locally: ssh-keygen -R \"(your-tunnel-hostname.com)\""
          echo "===================================================================================="
          echo "To continue the workflow, run 'touch /tmp/debug_done' in the SSH session."
          echo "Session will time out in ${{ github.event.inputs.ssh_timeout_minutes }} minutes."
          
          START_TIME=$(date +%s)
          TIMEOUT_SECONDS=$(( ${{ github.event.inputs.ssh_timeout_minutes }} * 60 ))
          
          while true; do
            if [ -f /tmp/debug_done ]; then
              echo "âœ… '/tmp/debug_done' detected. Ending debug session."
              sudo rm -f /tmp/debug_done
              break
            fi
            CURRENT_TIME=$(date +%s)
            ELAPSED=$(( CURRENT_TIME - START_TIME ))
            if [ $ELAPSED -ge $TIMEOUT_SECONDS ]; then
              echo "â³ SSH session timed out. Continuing workflow."
              break
            fi
            sleep 10
          done
          
          pkill -f cloudflared || true

      - name: 12. Unmount Virtual Filesystems
        if: always()
        run: |
          sudo umount -l "${{ env.CHROOT_DIR }}/dev/pts" || true
          sudo umount -l "${{ env.CHROOT_DIR }}/dev" || true
          sudo umount -l "${{ env.CHROOT_DIR }}/proc" || true
          sudo umount -l "${{ env.CHROOT_DIR }}/sys" || true

      - name: 13. âš¡ï¸ Create & Upload Backup
        if: success() && !cancelled() && (github.event.inputs.backup_mode == 'chroot' || github.event.inputs.backup_mode == 'all')
        run: |
          echo "--- Stopping services and creating backup ---"
          sudo chroot ${{ env.CHROOT_DIR }} bash -c 'command -v pm2 && pm2 stop all' || true
          pm2 stop python-app || true
          
          rclone config create ${{ env.B2_REMOTE_NAME }} b2 account "${{ env.B2_KEY_ID }}" key "${{ env.B2_APPLICATION_KEY }}"
          TIMESTAMP=$(date -u +'%Y%m%d-%H%M%S')
          NEW_BACKUP_FILE="${{ env.BACKUP_PREFIX }}${TIMESTAMP}.tar.zst"
          B2_FULL_PATH="${{ env.B2_REMOTE_NAME }}:${{ env.B2_BUCKET_NAME }}/${{ env.B2_REMOTE_PATH }}"
          EXCLUDE_OPTS="--exclude='./tmp' --exclude='./var/tmp' --exclude='./root/.cache' --exclude='./var/cache' --exclude='./var/log'"
          
          echo "Compressing with zstd and uploading to B2..."
          sudo tar -c ${EXCLUDE_OPTS} -f - -C ${{ env.CHROOT_DIR }} . | zstd -T0 -22 --long -c | rclone rcat ${B2_FULL_PATH}/${NEW_BACKUP_FILE} ${{ env.RCLONE_FLAGS }}
          
          echo "--- Cleaning up old backups (keeping last 2) ---"
          (
            set +e
            FILES_TO_DELETE=$(rclone lsjson ${B2_FULL_PATH}/ | jq -r '[.[] | select(.Name | test("minisys_backup_.*\\.tar\\.(zst|gz)$"))] | sort_by(.ModTime) | .[:-2][] | .Name' 2>/dev/null) || true
            if [[ -n "$FILES_TO_DELETE" && "$FILES_TO_DELETE" != "null" ]]; then
              echo "Deleting old backups:"
              echo "$FILES_TO_DELETE"
              for file_name in $FILES_TO_DELETE; do rclone deletefile "${B2_FULL_PATH}/${file_name}" || true; done
            else
              echo "No old backups to clean."
            fi
          )

      - name: 14. Final Cleanup
        if: always()
        run: |
          echo "--- Cleaning up runner environment ---"
          sudo rm -rf ${{ env.CHROOT_DIR }}
          rm -rf chatgpt-on-wechat
          sudo npm cache clean --force || true
          pip cache purge || true
          sudo docker system prune -a -f || true
          echo "âœ… Runner cleanup complete."