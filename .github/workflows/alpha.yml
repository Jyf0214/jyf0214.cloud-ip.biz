# å·¥ä½œæµåç§°
name: CI with Persistent Environment (v7.4 - Staggered Parallel Start)

# ... (on, concurrency, env éƒ¨åˆ†ä¸ä¹‹å‰ç‰ˆæœ¬å®Œå…¨ç›¸åŒ) ...
on:
  workflow_dispatch:
    inputs:
      create_backup_on_finish: { description: 'âœ… [æ ¸å¿ƒ] æ˜¯å¦åœ¨ç»“æŸæ—¶åˆ›å»ºç¯å¢ƒå¤‡ä»½? (è¿™å°†å½±å“è¿è¡Œæ—¶é•¿)', required: true, type: boolean, default: false }
      run_startup_script: { description: 'ğŸš€ [æ ¸å¿ƒ] æ˜¯å¦è‡ªåŠ¨æ‰§è¡ŒChrootå†…çš„æœåŠ¡å¯åŠ¨è„šæœ¬?', required: true, type: boolean, default: true }
      enable_ssh: { description: 'ğŸ [è°ƒè¯•] æ˜¯å¦å¯ç”¨SSHæ‰‹åŠ¨è°ƒè¯• (å°†æš‚åœè‡ªåŠ¨åŒ–) ?', required: true, type: boolean, default: false }
      run_launcher: { description: '  - æ˜¯å¦å¯åŠ¨ launcher æœåŠ¡?', type: boolean, default: false }
      run_redis: { description: '  - æ˜¯å¦å¯åŠ¨ Redis æœåŠ¡?', type: boolean, default: true }
      run_yunzai: { description: '  - æ˜¯å¦å¯åŠ¨ Yunzai-Bot æœåŠ¡?', type: boolean, default: true }
      run_loophole_webdav: { description: '  - æ˜¯å¦å¯åŠ¨ Loophole WebDAV éš§é“?', type: boolean, default: true }
      enable_napcat_tunnel: { description: '  - (Loophole) æ˜¯å¦é¢å¤–å¯ç”¨ Napcat å†…ç½‘ç©¿é€?', type: boolean, default: false }
      run_openlist: { description: '  - æ˜¯å¦å¯åŠ¨ openlist æœåŠ¡?', type: boolean, default: true }
      run_chmlfrp: { description: '  - æ˜¯å¦å¯åŠ¨ ChmlFrp æœåŠ¡?', type: boolean, default: true }
  schedule:
    - cron: '30 */6 * * *'
concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false
env:
  CHROOT_DIR: /mnt/minisys
  BACKUP_PREFIX: minisys_backup_
  B2_REMOTE_NAME: "b2_storage"
  B2_REMOTE_PATH: "backup"
  RCLONE_FLAGS: "--multi-thread-streams 4 --buffer-size 64M --fast-list --transfers 8 --progress"
  PAT: ${{ secrets.PAT }}
  LOOPHOLE_WEBDAV_USER: ${{ secrets.LOOPHOLE_WEBDAV_USER }}
  LOOPHOLE_WEBDAV_PASS: ${{ secrets.LOOPHOLE_WEBDAV_PASS }}
  LOOPHOLE_WEBDAV_HOSTNAME: ${{ secrets.LOOPHOLE_WEBDAV_HOSTNAME }}
  LOOPHOLE_NAPCAT_HOSTNAME: ${{ secrets.LOOPHOLE_NAPCAT_HOSTNAME }}
  NAPCATUSER: ${{ secrets.NAPCATUSER }}
  NAPCATPASS: ${{ secrets.NAPCATPASS }}
  B2_KEY_ID: ${{ secrets.B2_KEY_ID }}
  B2_APPLICATION_KEY: ${{ secrets.B2_APPLICATION_KEY }}
  B2_BUCKET_NAME: ${{ secrets.B2_BUCKET_NAME }}
  B2_DOWNLOAD_URL: ${{ secrets.B2_DOWNLOAD_URL }}

jobs:
  build-and-run-all:
    name: "Run All Services (v7.4 - Staggered Parallel)"
    runs-on: ubuntu-latest
    steps:
      - name: 1. æ£€å‡ºå·¥ä½œæµä»£ç 
        uses: actions/checkout@v4

      - name: 2. æœ€å¤§åŒ–è¿è¡Œå™¨ç£ç›˜ç©ºé—´
        run: sudo rm -rf /usr/share/dotnet /opt/ghc /usr/local/share/boost "$AGENT_TOOLSDIRECTORY"

      - name: 3. å®‰è£…åŸºç¡€ç³»ç»Ÿä¾èµ–
        run: sudo apt-get update && sudo apt-get install -y debootstrap rclone pigz zstd jq

      - name: 4. è®¾ç½® Python ç¯å¢ƒ
        uses: actions/setup-python@v4
        with: { python-version: "3.9" }

      - name: 5. å…‹éš† Python åº”ç”¨ä»“åº“
        run: git clone https://x-access-token:${{ env.PAT }}@github.com/Jyf0214/chatgpt-on-wechat.git

      - name: 6. ç¼“å­˜ Python ä¾èµ– (Pip)
        id: cache-pip
        uses: actions/cache@v4
        with:
          path: ./chatgpt-on-wechat/lib
          key: ${{ runner.os }}-pip-deps-${{ hashFiles('./chatgpt-on-wechat/requirements.txt', './chatgpt-on-wechat/requirements-optional.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-deps-

      # [ä¼˜åŒ–] å‡†å¤‡é˜¶æ®µåªæ¢å¤ Chroot å’Œå®‰è£… Runner çš„ PM2
      - name: 7. âš¡ï¸ å¹¶è¡Œå‡†å¤‡ï¼šæ¢å¤Chroot & å®‰è£…NodeJS/PM2
        id: prepare_core
        run: |
          CHROOT_LOG=$(mktemp); NODE_LOG=$(mktemp)
          ( echo "--- [å¹¶è¡ŒA] å¼€å§‹: æ¢å¤/åˆ›å»º Chroot ç¯å¢ƒ..."; set -eo pipefail; sudo mkdir -p ${{ env.CHROOT_DIR }}; rclone config create ${{ env.B2_REMOTE_NAME }} b2 account "${{ env.B2_KEY_ID }}" key "${{ env.B2_APPLICATION_KEY }}" download_url "${{ env.B2_DOWNLOAD_URL }}"; B2_FULL_PATH="${{ env.B2_REMOTE_NAME }}:${{ env.B2_BUCKET_NAME }}/${{ env.B2_REMOTE_PATH }}"; LATEST_BACKUP_FILENAME=$(rclone lsjson ${B2_FULL_PATH}/ | jq -r '[.[] | select(.Name | test("minisys_backup_.*\\.tar\\.(zst|gz)$"))] | sort_by(.ModTime) | .[-1].Name' 2>/dev/null); if [[ -n "$LATEST_BACKUP_FILENAME" && "$LATEST_BACKUP_FILENAME" != "null" ]]; then echo "   -> [å¹¶è¡ŒA] å‘ç°å¤‡ä»½: ${LATEST_BACKUP_FILENAME}."; rclone copyto "${B2_FULL_PATH}/${LATEST_BACKUP_FILENAME}" /tmp/backup.archive ${{ env.RCLONE_FLAGS }}; if [[ "${LATEST_BACKUP_FILENAME}" == *.zst ]]; then unzstd -c /tmp/backup.archive | sudo tar -xpf - -C ${{ env.CHROOT_DIR }}; else pigz -dc /tmp/backup.archive | sudo tar -xpf - -C ${{ env.CHROOT_DIR }}; fi; rm -f /tmp/backup.archive; echo "restored=true" > /tmp/chroot_status; else echo "   -> [å¹¶è¡ŒA] å¤‡ä»½æœªæ‰¾åˆ°. åˆ›å»ºå…¨æ–°ç³»ç»Ÿ..."; sudo debootstrap --variant=minbase jammy ${{ env.CHROOT_DIR }} http://archive.ubuntu.com/ubuntu/; echo "restored=false" > /tmp/chroot_status; fi; echo "--- [å¹¶è¡ŒA] âœ… Chroot ç¯å¢ƒå°±ç»ª ---"; ) > ${CHROOT_LOG} 2>&1 &
          CHROOT_PID=$!
          ( echo "--- [å¹¶è¡ŒB] å¼€å§‹: å®‰è£… Node.js & PM2..."; curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -; sudo apt-get install -y nodejs; sudo npm install -g pm2; echo "--- [å¹¶è¡ŒB] âœ… Node.js & PM2 å®‰è£…å®Œæ¯• ---"; ) > ${NODE_LOG} 2>&1 &
          NODE_PID=$!
          
          FAIL=0; wait ${CHROOT_PID}; CHROOT_EC=$?; echo "--- ğŸ“œ Chroot ä»»åŠ¡æ—¥å¿— ---"; cat ${CHROOT_LOG}; if [[ $CHROOT_EC -ne 0 ]]; then echo "âŒ Chroot ä»»åŠ¡å¤±è´¥!"; FAIL=1; fi
          wait ${NODE_PID}; NODE_EC=$?; echo "--- ğŸ“œ Node.js ä»»åŠ¡æ—¥å¿— ---"; cat ${NODE_LOG}; if [[ $NODE_EC -ne 0 ]]; then echo "âŒ Node.js ä»»åŠ¡å¤±è´¥!"; FAIL=1; fi
          if [[ $FAIL -eq 1 ]]; then exit 1; fi
          
          echo "âœ… æ ¸å¿ƒå‡†å¤‡ä»»åŠ¡æˆåŠŸ!"; CHROOT_STATUS=$(cat /tmp/chroot_status); echo "restored=${CHROOT_STATUS}" >> $GITHUB_OUTPUT

      - name: 8. æŒ‚è½½è™šæ‹Ÿæ–‡ä»¶ç³»ç»Ÿ
        run: |
          MNT_DIR=${{ env.CHROOT_DIR }}; sudo mount -t proc proc "${MNT_DIR}/proc"; sudo mount -o bind /dev "${MNT_DIR}/dev"; sudo mount -o bind /dev/pts "${MNT_DIR}/dev/pts"; sudo mount -o bind /sys "${MNT_DIR}/sys"

      - name: 9. [å¢å¼º] æ¸…ç†ä¸æ›´æ–° Chroot (å¦‚æœæ¢å¤è‡ªå¤‡ä»½)
        if: steps.prepare_core.outputs.restored == 'true'
        run: |
          echo "--- å¼€å§‹æ·±åº¦æ¸…ç† Chroot ç¯å¢ƒ ---"; sudo chroot ${{ env.CHROOT_DIR }} /bin/bash -c "apt-get clean -y&&apt-get autoclean -y&&apt-get autoremove -y&&rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* /root/.cache /root/.npm"
          echo "--- è‡ªåŠ¨æ›´æ–° Chroot å†…çš„ OpenList ---"; sudo tee ${{ env.CHROOT_DIR }}/tmp/update_openlist.sh > /dev/null << 'EOF'
          #!/usr/bin/env bash
          set -e; cd /root; apt-get update >/dev/null && apt-get install -y curl jq >/dev/null; LATEST_TAG=$(curl -s https://api.github.com/repos/OpenListTeam/OpenList/releases/latest|jq -r '.tag_name'|head -1); ARCH=amd64; TARBALL="openlist-linux-${ARCH}.tar.gz"; DOWNLOAD_URL="https://github.com/OpenListTeam/OpenList/releases/download/${LATEST_TAG}/${TARBALL}"; wget -qO "${TARBALL}" "${DOWNLOAD_URL}"; TMP_DIR=$(mktemp -d); trap "rm -rf ${TMP_DIR}" EXIT; tar -zxf "${TARBALL}" -C "${TMP_DIR}"; mv "${TMP_DIR}/openlist" ./openlist; chmod +x ./openlist; rm -f "${TARBALL}"; echo "âœ… OpenList å·²æ›´æ–°è‡³ ${LATEST_TAG}"; EOF
          sudo chmod +x ${{ env.CHROOT_DIR }}/tmp/update_openlist.sh; sudo chroot ${{ env.CHROOT_DIR }} /tmp/update_openlist.sh

      # [ç»ˆæä¼˜åŒ–] å¹¶è¡Œå¯åŠ¨ Chroot æœåŠ¡ å’Œ Python åº”ç”¨
      - name: 10. âš¡ï¸ å¹¶è¡Œå¯åŠ¨æ‰€æœ‰æœåŠ¡
        run: |
          # --- åå°ä»»åŠ¡: å¯åŠ¨ Chroot å†…çš„æœåŠ¡ ---
          if [[ "${{ github.event.inputs.run_startup_script }}" == "true" ]]; then
            echo "--- [åå°] æ­£åœ¨å¯åŠ¨ Chroot å†…éƒ¨æœåŠ¡..."
            sudo tee ${{ env.CHROOT_DIR }}/tmp/startup.sh > /dev/null << 'EOF'
            #!/bin/bash
            set -e
            export RUN_LAUNCHER='${{ github.event.inputs.run_launcher || (github.event_name == 'schedule' && 'true') }}'; export RUN_REDIS='${{ github.event.inputs.run_redis || (github.event_name == 'schedule' && 'true') }}'; export RUN_YUNZAI='${{ github.event.inputs.run_yunzai || (github.event_name == 'schedule' && 'true') }}'; export RUN_LOOPHOLE_WEBDAV='${{ github.event.inputs.run_loophole_webdav || (github.event_name == 'schedule' && 'true') }}'; export RUN_OPENLIST='${{ github.event.inputs.run_openlist || (github.event_name == 'schedule' && 'true') }}'; export RUN_CHMLFRP='${{ github.event.inputs.run_chmlfrp || (github.event_name == 'schedule' && 'true') }}'; export ENABLE_NAPCAT_TUNNEL='${{ github.event.inputs.enable_napcat_tunnel || 'false' }}'
            export LOOPHOLE_WEBDAV_USER='${{ env.LOOPHOLE_WEBDAV_USER }}'; export LOOPHOLE_WEBDAV_PASS='${{ env.LOOPHOLE_WEBDAV_PASS }}'; export LOOPHOLE_WEBDAV_HOSTNAME='${{ env.LOOPHOLE_WEBDAV_HOSTNAME }}'; export LOOPHOLE_NAPCAT_HOSTNAME='${{ env.LOOPHOLE_NAPCAT_HOSTNAME }}'; export NAPCATUSER='${{ env.NAPCATUSER }}'; export NAPCATPASS='${{ env.NAPCATPASS }}'
            export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/node_modules/.bin; HOME_DIR="/root"
            if ! command -v pm2 &> /dev/null; then npm install -g pm2; fi; echo "1. æ¸…ç†æ—¥å¿—..." && pm2 flush && find ${HOME_DIR} -name "*.log" -type f -delete
            if [[ "$RUN_YUNZAI" == "true" ]]; then echo "å¯åŠ¨ Yunzai..."; [ -d "${HOME_DIR}/Yunzai" ] && (cd "${HOME_DIR}/Yunzai" && pm2 start app.js --name "yunzai-app"); else echo "è·³è¿‡ Yunzai"; fi
            # ... å…¶ä»–æœåŠ¡å¯åŠ¨é€»è¾‘ ...
            pm2 save && pm2 ls
            EOF
            sudo chmod +x ${{ env.CHROOT_DIR }}/tmp/startup.sh
            # ä½¿ç”¨ & è®© Chroot è„šæœ¬åœ¨åå°è¿è¡Œ
            (sudo chroot ${{ env.CHROOT_DIR }} /tmp/startup.sh) &
          else
            echo "--- [è·³è¿‡] æ ¹æ®è®¾ç½®ï¼Œä¸å¯åŠ¨ Chroot å†…éƒ¨æœåŠ¡ã€‚ ---"
          fi

          # --- å‰å°ä»»åŠ¡: å®‰è£…å¹¶å¯åŠ¨ Python åº”ç”¨ ---
          echo "--- [å‰å°] åå°æ­£åœ¨å¯åŠ¨ChrootæœåŠ¡, å‰å°å¼€å§‹å‡†å¤‡ Python åº”ç”¨..."
          cd chatgpt-on-wechat
          echo "[å‰å°] æ­£åœ¨å®‰è£… Python ä¾èµ– (å¯èƒ½è€—æ—¶è¾ƒé•¿)..."
          python -m pip install --upgrade pip
          pip install -r requirements-optional.txt --target ./lib --cache-dir ~/.cache/pip || true
          pip install -r requirements.txt --target ./lib --cache-dir ~/.cache/pip || true
          
          echo "[å‰å°] ä¾èµ–å®‰è£…å®Œæˆ, å¯åŠ¨ Python åº”ç”¨..."
          export PYTHONPATH=$(pwd)/lib
          pm2 start "python3 app.py" --name "python-app"
          
          echo "âœ… Python åº”ç”¨å·²å¯åŠ¨ã€‚ç­‰å¾…åå° Chroot ä»»åŠ¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰å®Œæˆ..."
          wait # ç­‰å¾…æ‰€æœ‰åå°å­è¿›ç¨‹å®Œæˆ
          echo "âœ… æ‰€æœ‰å¯åŠ¨ä»»åŠ¡å®Œæˆã€‚"
          pm2 ls

      - name: 11. [è‡ªåŠ¨åŒ–/æ‰‹åŠ¨] ç­‰å¾…æˆ–è°ƒè¯•
        if: github.event.inputs.enable_ssh == 'false'
        env:
          RUNTIME_MINUTES: ${{ github.event.inputs.create_backup_on_finish == 'true' && 300 || 350 }}
        run: |
          echo "ğŸš€ æ‰€æœ‰æœåŠ¡å·²æ ¹æ®è®¾ç½®å¯åŠ¨ã€‚å·¥ä½œæµå°†æš‚åœ ${RUNTIME_MINUTES} åˆ†é’Ÿ..."
          sleep ${RUNTIME_MINUTES}m
          echo "â³ è§„å®šè¿è¡Œæ—¶é—´å·²åˆ°ã€‚"
      - name: 11. [æ‰‹åŠ¨è°ƒè¯•è·¯å¾„]
        if: github.event.inputs.enable_ssh == 'true'
        uses: lhotari/action-upterm@v1
        with: { limit-access-to-actor: true, wait-timeout-minutes: 350 }

      - name: 12. åœæ­¢æ‰€æœ‰æœåŠ¡
        if: always()
        run: |
          echo "--- æ­£åœ¨åœæ­¢æ‰€æœ‰æœåŠ¡ ---"
          # åœæ­¢ Runner ä¸Šçš„ Python åº”ç”¨
          pm2 stop python-app || echo "Python app æœªè¿è¡Œæˆ–å·²åœæ­¢ã€‚"
          # åœæ­¢ Chroot å†…çš„æ‰€æœ‰æœåŠ¡
          sudo chroot ${{ env.CHROOT_DIR }} bash -c 'command -v pm2 && pm2 stop all' || echo "Chroot å†… PM2 æœªè¿è¡Œæˆ–å·²åœæ­¢ã€‚"
          echo "âœ… æ‰€æœ‰æœåŠ¡å·²åœæ­¢ã€‚"

      - name: 13. å¸è½½è™šæ‹Ÿæ–‡ä»¶ç³»ç»Ÿ
        if: always()
        run: |
          sudo umount -l "${{ env.CHROOT_DIR }}/dev/pts" || true; sudo umount -l "${{ env.CHROOT_DIR }}/dev" || true
          sudo umount -l "${{ env.CHROOT_DIR }}/proc" || true; sudo umount -l "${{ env.CHROOT_DIR }}/sys" || true

      - name: 14. âš¡ï¸ [æé€Ÿ] åˆ›å»ºç‰ˆæœ¬åŒ–å¤‡ä»½
        if: success() && !cancelled() && github.event.inputs.create_backup_on_finish == 'true'
        run: |
          echo "--- ä½¿ç”¨ zstd-19 åˆ›å»ºå¤‡ä»½å¹¶ä¸Šä¼ è‡³ B2 ---"
          rclone config create ${{ env.B2_REMOTE_NAME }} b2 account "${{ env.B2_KEY_ID }}" key "${{ env.B2_APPLICATION_KEY }}"
          TIMESTAMP=$(date -u +'%Y%m%d-%H%M%S')
          NEW_BACKUP_FILE="${{ env.BACKUP_PREFIX }}${TIMESTAMP}.tar.zst"
          B2_FULL_PATH="${{ env.B2_REMOTE_NAME }}:${{ env.B2_BUCKET_NAME }}/${{ env.B2_REMOTE_PATH }}"
          EXCLUDE_OPTS="--exclude='./tmp' --exclude='./var/tmp' --exclude='./root/.cache' --exclude='./var/cache' --exclude='./var/log'"
          sudo tar -c ${EXCLUDE_OPTS} -f - -C ${{ env.CHROOT_DIR }} . | zstd -T0 -19 -c | rclone rcat ${B2_FULL_PATH}/${NEW_BACKUP_FILE} ${{ env.RCLONE_FLAGS }}
          echo "âœ… æ–°å¤‡ä»½ä¸Šä¼ æˆåŠŸã€‚"
          echo "--- æ¸…ç† B2 ä¸Šçš„æ—§å¤‡ä»½ (ä¿ç•™2ä¸ªæœ€æ–°) ---"
          FILES_TO_DELETE=$(rclone lsjson ${B2_FULL_PATH}/ | jq -r '[.[] | select(.Name | test("minisys_backup_.*\\.tar\\.(zst|gz)$"))] | sort_by(.ModTime) | .[:-2][] | .Name' 2>/dev/null)
          if [[ -n "$FILES_TO_DELETE" && "$FILES_TO_DELETE" != "null" ]]; then
            echo "å°†è¦åˆ é™¤: $FILES_TO_DELETE"
            for file_name in $FILES_TO_DELETE; do rclone deletefile "${B2_FULL_PATH}/${file_name}"; done
            echo "âœ… æ—§å¤‡ä»½æ¸…ç†å®Œæ¯•ã€‚"
          else echo "æ— éœ€æ¸…ç†ã€‚"; fi

      - name: 15. æ¸…ç†è¿è¡Œå™¨æ®‹ç•™æ–‡ä»¶
        if: always()
        run: |
          echo "--- æ¸…ç†è¿è¡Œå™¨ç¯å¢ƒ ---"
          sudo rm -rf ${{ env.CHROOT_DIR }}; rm -rf chatgpt-on-wechat
          sudo npm cache clean --force || true; pip cache purge || true
          echo "âœ… è¿è¡Œå™¨æ¸…ç†å®Œæˆã€‚"